total = total + (each - x[i])^2
}
print(total)
}
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
lm(x~y)
B1 <- lm(y~x)$x
B1
B1 <- lm(y~x)[2]
B1
z <- -1.713/-0.04462
z
Var(y)
Var(x)
var(y)
var(x)
var(y)/var(x)
2*(sd(y)/sd(x))
cor(y,x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x-1)
lm(y ~ x)
lm(y ~ x-1)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xc <- (x-mean(x))/sd(x)
xc
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
n <- length(x)
y <-c(0.573,0.8,0.36,0.44)
for (each in y){
total <- 0
print(each)
#print(x[i])
#print(w[i])
for (i in 1:n){
total = total + (each - x[i])^2
}
print(total)
}
x <- 0.5*(1/1.5)
x
1/1.5
x <- 0.5*(1/0.5)
x
library(UsingR)
data(diamond)
library(ggplot2)
library(UsingR)
data(diamond)
library(ggplot2)
plot(diamond$carat,diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black" , cex = 1.1, pch = 21, frame = FALSE)
abline(lm(price ~ carat, data = diamond), lwd = 2)
fit <- lm(price ~ carat, data = diamond)
coef(fit)
fit2 <- lm(price ~ I(carat - mean(carat)), data = diamond)
coef(fit2)
fit3 <- lm(price ~ I(carat * 10), data = diamond)
coef(fit3)
newx <- c(0.16, 0.27, 0.34)
coef(fit)[1] + coef(fit)[2] * newx
predict(fit, newdata = data.frame(carat = newx))
data(diamond)
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(fit, lwd = 2)
points(diamond$carat, predict(fit), pch = 19, col = "red")
lines(c(0.16, 0.16, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.16,
coef(fit)[1] + coef(fit)[2] * 0.16))
lines(c(0.27, 0.27, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.27,
coef(fit)[1] + coef(fit)[2] * 0.27))
lines(c(0.34, 0.34, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.34,
coef(fit)[1] + coef(fit)[2] * 0.34))
text(newx, rep(250, 3), labels = newx, pos = 2)
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
fit
e <- resid(fit)
e
yhat <- predict(fit)
yhat
max(abs(e -(y - yhat)))
max(abs(e - (y - coef(fit)[1] - coef(fit)[2] * x)))
### Residuals are the signed length of the red lines
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 2, pch = 21,frame = FALSE)
abline(fit, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(y[i], yhat[i]), col = "red" , lwd = 2)
plot(x, e,
xlab = "Mass (carats)",
ylab = "Residuals (SIN $)",
bg = "lightblue",
col = "black", cex = 2, pch = 21,frame = FALSE)
abline(h = 0, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
x = runif(100, -3, 3); y = x + sin(x) + rnorm(100, sd = .2);
library(ggplot2)
g = ggplot(data.frame(x = x, y = y), aes(x = x, y = y))
g = g + geom_smooth(method = "lm", colour = "black")
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g
g = ggplot(data.frame(x = x, y = resid(lm(y ~ x))),
aes(x = x, y = y))
g = g + geom_hline(yintercept = 0, size = 2);
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g = g + xlab("X") + ylab("Residual")
g
x <- runif(100, 0, 6); y <- x + rnorm(100,  mean = 0, sd = .001 * x);
g = ggplot(data.frame(x = x, y = y), aes(x = x, y = y))
g = g + geom_smooth(method = "lm", colour = "black")
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g
g = ggplot(data.frame(x = x, y = resid(lm(y ~ x))),
aes(x = x, y = y))
g = g + geom_hline(yintercept = 0, size = 2);
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g = g + xlab("X") + ylab("Residual")
g
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
summary(fit)$sigma
sqrt(sum(resid(fit)^2) / (n - 2))
summary(fit)
op <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))
for(i in 1:4) {
ff[2:3] <- lapply(paste0(c("y","x"), i), as.name)
plot(ff, data = anscombe, col = "red", pch = 21, bg = "orange", cex = 1.2,
xlim = c(3, 19), ylim = c(3, 13))
abline(mods[[i]], col = "blue")
}
mtext("Anscombe's 4 Regression data sets", outer = TRUE, cex = 1.5)
par(op)
library(UsingR); data(diamond)
diamond
y <- diamond$price; x <- diamond$carat; n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y)-beta1*meand(x)
beta0 <- mean(y)-beta1*mean(x)
e <- y - beta0-beta1*x
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
seBeta0 <- (1/n + mean(x)^2/ssx)^0.5*sigma
seBeta1 <- sigma/sqrt(ssx)
tBeta0 <- beta0 / seBeta0
tBeta1 <- beta1 / seBeta1
pBeta0 <- 2*pt(abs(tBeta0), df=n-2, lower.tail= FALSE)
pBeta1 <- 2*pt(abs(tBeta1), df=n-2, lower.tail = FALSE)
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Std. Error", "t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)", "x")
coefTable
fit <- lm(y ~ x)
fit$coeffients
summary(fit)$coeffients
fit$coefficients
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
fit$df
sumCoef[1,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[1, 2]
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]) / 10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
g
### Linear model with two variables and an intercept
n <- 100; x = rnorm(n); x2 = rnorm(n); x3 = rnorm(n)
y <- x + x2 + x3 + rnorm(n, sd = .1)
e <- function(a,b){a-sum(a*b)/sum(b^2)*b}
ey <- e(e(y,x2),e(x3,x2))
ex <- e(e(x,x2),e(x3,x2))
sum(ey*ex)/sum(ex^2)
coef(lm(y ~ x + x2 + x3 -1)) # the -1 removes the intercept term
### Showing thar order doesn't matter
ey <- e(e(y,x3),e(x2,x3))
ex <- e(e(x,x3),e(x2,x3))
sum(ey*ex)/sum(ex^2)
ey <- resid(lm(y ~ x2 + x3 -1))
ex <- resid(lm(x ~ x2 + x3 -1))
sum(ey*ex)/sum(ex^2)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
fit
summary(fit)$Coefficients
Summary(fit)$Coefficients
Summary(fit)$coefficients
summary(fit)$coefficients
Coef <- summary(fit)$coefficients
Coef[1,1]
Coef[2,1]
n <- length(x)
n
e <- y - Coef[1,1] - Coef[2,1]*x
sigma <- sqrt(sum(e^2)/(n-2))
data(mtcars)
mtcars
wt <- mtcars$wt ; mpg <- mtcars$mpg
?fit
?lm
fit <- lm(mpg ~ wt, data=mtcars)
newdata <- data.frame(wt = mean(wt))
newdata
?predict
x <- predict(fit, newdata, interval=("confidence"))
x
fit
newdata
?mtcars
# Q1
###  x as the predictor and y as as the outcome find P-value
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)$coefficients
Coef <- summary(fit)$coefficients
n <- length(x)
e <- y - Coef[1,1] - Coef[2,1]*x
sigma <- sqrt(sum(e^2)/(n-2))
data(mtcars)
### fit a linear regression model of weight (predictor) on mpg (outcome)
### Get a 95% confidence interval for the expected mpg at the average weight
### What is the lower endpoint?
wt <- mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
newdata <- data.frame(wt = mean(wt))
x <- predict(fit, newdata, interval=("confidence"))
x
wt <- mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
newdata <- data.frame(wt = 3000/1000)
x <- predict(fit, newdata, interval=("prediction"))
x
newdata <- data.frame(wt = 2000/1000)
x <- predict(fit, newdata, interval=("confidence"))
x
wt <- (1/2)*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef
fit$df
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
sumCoef[2,1]+c(-1,1)*qt(0.95,df=fit$df)*sumCoef[2,2]
wt <- (1/2)*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
summary(fit)$coefficients
wt <- mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
summary(fit)$coefficients
wt <- mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
summary(fit)$coefficients
wt <- (1/2)*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef
data(mtcars)
wt <- (1/2)*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
summary(fit)$coefficients
wt1 <- mtcars$wt ; mpg1 <- mtcars$mpg
fit <- lm(mpg1 ~ wt1, data=mtcars)
summary(fit)$coefficients
wt1 <- mtcars$wt ; mpg1 <- mtcars$mpg
fit1 <- lm(mpg1 ~ wt1, data=mtcars)
summary(fit1)$coefficients
wt <- (1/2)*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef
wt2 <- mtcars$wt+2 ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt2, data=mtcars)
summary(fit)$coefficients
fit
fit2 <- lm(mpg ~ wt2, data=mtcars)
summary(fit2)$coefficients
wt1 <- mtcars$wt ; mpg1 <- mtcars$mpg
fit1 <- lm(mpg1 ~ wt1, data=mtcars)
summary(fit1)$coefficients
fit1
fit2
# Q1
###  x as the predictor and y as as the outcome find P-value
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)$coefficients
# Q2
### Consider the previous problem, give the estimate of the residual standard deviation.
Coef <- summary(fit)$coefficients
n <- length(x)
e <- y - Coef[1,1] - Coef[2,1]*x
sigma <- sqrt(sum(e^2)/(n-2))
summary(fit)$coefficients
sigma
data(mtcars)
### fit a linear regression model of weight (predictor) on mpg (outcome)
### Get a 95% confidence interval for the expected mpg at the average weight
### What is the lower endpoint?
wt1 <- mtcars$wt ; mpg1 <- mtcars$mpg
fit1 <- lm(mpg1 ~ wt1, data=mtcars)
summary(fit1)$coefficients
newdata <- data.frame(wt = mean(wt))
x <- predict(fit, newdata, interval=("confidence"))
x
data(mtcars)
### fit a linear regression model of weight (predictor) on mpg (outcome)
### Get a 95% confidence interval for the expected mpg at the average weight
### What is the lower endpoint?
wt <- mtcars$wt ; mpg<- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
summary(fit1)$coefficients
newdata <- data.frame(wt = mean(wt))
x <- predict(fit, newdata, interval=("confidence"))
x
data(mtcars)
### fit a linear regression model of weight (predictor) on mpg (outcome)
### A new car is coming weighing 3000 pounds
### Construct a 95% prediction interval for its mpg
### What is the upper endpoint?
wt <- mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
newdata <- data.frame(wt = 3000/1000)
x <- predict(fit, newdata, interval=("prediction"))
x
data(mtcars)
### a linear regression model with mpg as predicted by weight (in 1,000 lbs)
### A “short” ton is defined as 2,000 lbs.
### Construct a 95% confidence interval for the expected change in mpg per 1 short ton increase in weight.
### Give the lower endpoint.
### to get an increase of 1 short tonne, divide by 2
wt <- (1/2)*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
lm(y ~ offset(x))
fit <- lm(mpg ~ wt, mtcars)
anova(fit)
fit <- lm(mpg ~ wt, mtcars)
fit2 <- lm(mpg ~ offset(wt), mtcars)
a <- summary(fit)
a
wt <- (1/2)*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
sumCoef[2,1]+c(-1,1)*qt(0.95,df=fit$df)*sumCoef[2,2]
sumCoef[2,1]+c(-1,1)*qt(0.95,df=fit$df)*sumCoef[2,2]
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
summary(fit)$coefficients
wt <- 2*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
fit <- lm(mpg ~ wt, data=mtcars)
data(mtcars)
### a linear regression model with mpg as predicted by weight (in 1,000 lbs)
### A “short” ton is defined as 2,000 lbs.
### Construct a 95% confidence interval for the expected change in mpg per 1 short ton increase in weight.
### Give the lower endpoint.
### to get an increase of 1 short tonne, divide by 2
wt <- 2*mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
sumCoef[2,1]+c(-1,1)*qt(0.95,df=fit$df)*sumCoef[2,2]
wt <- mtcars$wt ; mpg <- mtcars$mpg
fit <- lm(mpg ~ wt, data=mtcars)
sumCoef <- summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(0.95,df=fit$df)*sumCoef[2,2]
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
summary(fit)$coefficients
library(datasets);
data(swiss); require(stats); require(graphics)
pairs(swiss, panel = panel.smooth, main = "Swiss data", col = 3 + (swiss$Catholic > 50))
summary(lm(Fertility ~ . , data = swiss))
summary(lm(Fertility ~ Agriculture, data = swiss))$coefficients
runif(n, -.1, .1
runif(n, -.1, .1)
runif(n, -.1, .1)
n <- 100; x2 <- 1 : n; x1 <- .01 * x2 + runif(n, -.1, .1); y = -x1 + x2 + rnorm(n, sd = .01)
runif(n, -.1, .1)
?runif
summary(lm(y ~ x1))$coef
summary(lm(y ~ x1 + x2))$coef
par(mfrow = c(1, 2))
plot(x1, y, pch=21,col="black",bg=topo.colors(n)[x2], frame = FALSE, cex = 1.5)
title('Unadjusted, color is X2')
abline(lm(y ~ x1), lwd = 2)
plot(resid(lm(x1 ~ x2)), resid(lm(y ~ x2)), pch = 21, col = "black", bg = "lightblue", frame = FALSE, cex = 1.5)
title('Adjusted')
title('Adjusted')
abline(0, coef(lm(y ~ x1 + x2))[2], lwd = 2)
z <- swiss$Agriculture + swiss$Education
lm(Fertility ~ . + z, data = swiss)
require(datasets);data(InsectSprays)
require(stats); require(graphics)
boxplot(count ~ spray, data = InsectSprays,
xlab = "Type of spray", ylab = "Insect count",
main = "InsectSprays data", varwidth = TRUE, col = "lightgray")
summary(lm(count ~ spray, data = InsectSprays))$coef
summary(lm(count ~
I(1 * (spray == 'B')) + I(1 * (spray == 'C')) +
I(1 * (spray == 'D')) + I(1 * (spray == 'E')) +
I(1 * (spray == 'F'))
, data = InsectSprays))$coef
lm(count ~
I(1 * (spray == 'B')) + I(1 * (spray == 'C')) +
I(1 * (spray == 'D')) + I(1 * (spray == 'E')) +
I(1 * (spray == 'F')) + I(1 * (spray == 'A')), data = InsectSprays)
summary(lm(count ~ spray - 1, data = InsectSprays))$coef
?ave
ave(InsectSprays$count, InsectSprays$spray)
unique(ave(InsectSprays$count, InsectSprays$spray))
spary2 <- relevel(InsectSprays$spray,"C")
spary2
spray2 <- relevel(InsectSprays$spray,"C")
spray2
View(InsectSprays)
summary(lm(count ~ spray2, data = InsectSprays))$coef
spray2
fit <- lm(count ~ spray, data = InsectSprays) #A is ref
bbmbc <- coef(fit)[2] - coef(fit)[3] #B - C
coef(fit)[2]
coef(fit)[3]
temp <- summary(fit)
temp
temp$cov.unscaled[2, 2]
se <- temp$sigma * sqrt(temp$cov.unscaled[2, 2] + temp$cov.unscaled[3,3] - 2 *temp$cov.unscaled[2,3])
t <- (bbmbc) / se
se
t
t <- (bbmbc) / se
t
p <- pt(-abs(t), df = fit$df)
p
out <- c(bbmbc, se, t, p)
ames(out) <- c("B - C", "SE", "T", "P")
names(out) <- c("B - C", "SE", "T", "P")
round(out, 3)
spray2 <- relevel(InsectSprays$spray,"C")
summary(lm(count ~ spray2, data = InsectSprays))$coef
fit$df
setwd("D:/JOHNS HOPKINS Data Science Program/Regression Models/Rmd")
hunger <- read.csv("hunger.csv")
hunger <- hunger[hunger$Sex!="Both sexes",]
head(hunger)
lm1 <- lm(hunger$Numeric ~ hunger$Year)
plot(hunger$Year,hunger$Numeric,pch=19,col="blue")
abline(lm1, lwd = 2)
lines(hunger$Year,lm1$fitted,lwd=3,col="darkgrey")
lm1$fitted
points(hunger$Year,hunger$Numeric,pch=19,col=((hunger$Sex=="Male")*1+1))
lmM <- lm(hunger$Numeric[hunger$Sex=="Male"] ~ hunger$Year[hunger$Sex=="Male"])
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"] ~ hunger$Year[hunger$Sex=="Female"])
plot(hunger$Year,hunger$Numeric,pch=19)
points(hunger$Year,hunger$Numeric,pch=19,col=((hunger$Sex=="Male")*1+1))
lines(hunger$Year[hunger$Sex=="Male"],lmM$fitted,col="black",lwd=3)
lines(hunger$Year[hunger$Sex=="Female"],lmF$fitted,col="red",lwd=3)
lmBoth <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex)
plot(hunger$Year,hunger$Numeric,pch=19)
points(hunger$Year,hunger$Numeric,pch=19,col=((hunger$Sex=="Male")*1+1))
lmBoth$coeff
lmBoth$coeff[1]
lmBoth$coeff[2]
abline(c(lmBoth$coeff[1],lmBoth$coeff[2]),col="red",lwd=3)
abline(c(lmBoth$coeff[1] + lmBoth$coeff[3],lmBoth$coeff[2] ),col="black",lwd=3)
lmBoth <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex + hunger$Sex*hunger$Year)
plot(hunger$Year,hunger$Numeric,pch=19)
points(hunger$Year,hunger$Numeric,pch=19,col=((hunger$Sex=="Male")*1+1))
lmBoth$coeff
lmBoth$coeff[1]
abline(c(lmBoth$coeff[1],lmBoth$coeff[2]),col="red",lwd=3)
abline(c(lmBoth$coeff[1] + lmBoth$coeff[3],lmBoth$coeff[2] +lmBoth$coeff[4]),col="black",lwd=3)
summary(lmBoth)
summary(lmBoth)$coeff
